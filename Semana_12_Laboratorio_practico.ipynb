{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "1ac59116195c7c779063ab4bec34e52b46147eaf4748310bb1c8dffc3d97fd3b"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('python=3.8': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Semana 12 - Laboratorio practico.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCgsBpGza_ju"
      },
      "source": [
        "# Laboratorio\n",
        "El objetivo del siguiente laboratorio es investigar los diferentes algoritmos vistos durante la clase.\n",
        "Probar qué sucede cuando tratamos a las variables con atributos faltantes como una clase propia."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0YZhiVM_lqwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iudhdS3ya_j6"
      },
      "source": [
        "# El dataset\n",
        "El dataset está relacionado a una campaña de márketing de un banco portugués. La campaña consistió en llamadas telefónicas. A menudo, se requería de múltiples llamadas para determinar si el cliente se suscribiría a un depósito a plazo en el banco (la variable objetivo)\n",
        "Cada línea representa un cliente. Adicionalmente a la información de cada cliente, se cuenta con indicadores sociales y económicos al momento del último contacto con el cliente antes de la decisión de contratar o no el depósito.\n",
        "\n",
        "Para descargarlo ingresar al siguiente [link](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing) y descargar el dataset bank-additional.csv\n",
        "\n",
        "*se puede usar el bank-additional-full.csv despues de haber completado el laboratorio si se quiere probar con mas puntos de data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcVoaukDa_j7"
      },
      "source": [
        "# Lectura de Data\n",
        "El dataset se encuentra en un archivo csv donde los separadores son “;”. Se puede importar usando la librería pandas y el método ```read_csv```.\n",
        "[referencia](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNq_XVYZa_j9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKXPreATa_kB"
      },
      "source": [
        "# Analisis de la data\n",
        "Antes de preprocesar la data, es necesario determinar con qué información contamos. En el archivo ```bank-additional-names.txt``` se cuenta con la descripción de cada una de las variables de entrada. Si no se contara con esta informacion, es necesario verificar los rangos de los datos numericos, registros unicos para los datos categoricos y determinar que consideraremos como registros nulos.\n",
        "\n",
        "Para ello podemos usar las funciones de pandas [```describe```](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) para los datos numericos y [```unique```](https://pandas.pydata.org/docs/reference/api/pandas.unique.html) para los datos categoricos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkmaAKcza_kD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-CDdG6ya_kE"
      },
      "source": [
        "# Preprocesamiento\n",
        "Para empezar separamos las variables de entradas de nuestra variable de salida. Obtenemos nuestras variables `X` e `Y`. La `Y` en este caso será la columna `‘y’` la cual nos indica si se contrató el depósito o no.\n",
        "\n",
        "`Y = data[‘y’] #seleccionamos solo la columna ‘y’ de la data cargada`\n",
        "\n",
        "`X = data.drop(columns=[‘y’]) #eliminamos la columna ‘y’ de la data y nos quedamos con todo el resto de columnas.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhv8Ilgja_kF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G1lDN_pa_kG"
      },
      "source": [
        "\n",
        "Antes de ejecutar cualquier algoritmo de preprocesamiento, debemos dividir nuestra data en train y test. Esto lo realizamos para no introducir ningun tipo de cesgo en la data que usaremos para evaluar la performance del modelo.\n",
        "\n",
        "Debemos tomar nota del preprocesamiento que haremos a la data de entrenamiento para replicarlo en la data de evaluacion, ya que los modelos de ML estaran entrenados con la data preprocesada. Lo mismo ocurrira cuando querramos predecir. Cada nueva informacion que pasemos a los modelos de ML debemos preprocesarlas de la misma forma que la data de entrenamiento\n",
        "\n",
        "Para ello podemos usar [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHDcvmJa_kG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0J8Ur-ba_kH"
      },
      "source": [
        "Ahora si podemos empezar con el preprocesamiento.\n",
        "Primero verificamos que no falten valores. En una primera version consideremos los \"unknown\" como clases validas. En una siguiente iteracion usaremos tecnicas de imputacion.\n",
        "\n",
        "A continuacion, recordemos que si son variables numericas, generalmente las estandarizamos ([`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n",
        "Si son variables categoricas, evaluamos si son nominal u ordinales.\n",
        "* Si son nominal, normalmente usamos el One-Hot encoding [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), o [`pandas.get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
        "* Si son ordinales, el ordinal encoding. ([`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html))\n",
        "\n",
        "Para cada uno de los metodos debemos hacer fit sobre la data de entrenamiento y transform tanto a la data de entrenamiento como a la de evaluacion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG-Smu-la_kH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gElzmVt7a_kI"
      },
      "source": [
        "# Modelos de ML\n",
        "\n",
        "Procedemos a configurar los multiples de modelos de ML que usaremos. Simplemente compararemos varias versiones.\n",
        "Por ejemplo:\n",
        "\n",
        "```\n",
        "models = [\n",
        "          ('LogReg', LogisticRegression()), \n",
        "          ('RF', RandomForestClassifier()),\n",
        "          ('KNN', KNeighborsClassifier()),\n",
        "          ('Tree', DecisionTreeClassifier()\n",
        "          ('Bagg', BaggingClassifier()\n",
        "          ('Ada', AdaBoostClassifier())\n",
        "\n",
        "```\n",
        "\n",
        "Para ello usamos un `for` y dentro llamamos el metodo `fit` de cada modelo. Tambien llamamos el `score` usando la data de evaluacion para obtener metricas.\n",
        "\n",
        "No nos limitemos a los modelos aqui presentados, pueden agregar los suyos por su cuenta y obviamente cambiar los hiperparametros de cada uno de ellos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbOjYmgQa_kJ"
      },
      "source": [
        "#Insertar entrenamiento de los modelos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6wg6L-Da_kJ"
      },
      "source": [
        "Evaluamos los modelos y podemos realizar una tabla comparativa con el accuracy. En caso se quiera un mayor detalle podemos usar la matriz de confusion. Obtenemos las predicciones usando el metodo `predict` de los modelos obtenidos y usando [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) obtenemos la matriz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-FvhOjDa_kJ"
      },
      "source": [
        "#Evaluando el Modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqxqo_VRa_kK"
      },
      "source": [
        "# Experimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKotbNbka_kK"
      },
      "source": [
        "# Imputacion de valores\n",
        "Ahora, en lugar de considerar los valores \"unknown\" como validos, los consideraremos nulos y los imputaremos.\n",
        "Para ello podemos usar el [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) o el [`KNNImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV8eKhZHa_kL"
      },
      "source": [
        "#Imputacion de Valores y Comparacion\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwLTBEIBa_kP"
      },
      "source": [
        "# PCA\n",
        "\n",
        "Evaluar usando [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) los componentes principales y evaluar cuantos componentes son necesarios y probar haciendo las predicciones usando menos componentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "513et2yaa_kW"
      },
      "source": [
        "#PCA y Comparacion"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}